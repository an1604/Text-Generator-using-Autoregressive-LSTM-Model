{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b0e6d-6318-47e1-b729-bf9c7d067a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/app/data/epirecipes/full_format_recipes.json') as json_data:\n",
    "    recipe_data = json.load(json_data)\n",
    "filtered_data = [\n",
    "    'Recipe for ' + x['title']+ ' | ' + ' '.join(x['directions'])\n",
    " for x in recipe_data\n",
    " if 'title' in x\n",
    " and x['title'] is not None\n",
    " and 'directions' in x\n",
    " and x['directions'] is not None\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67300d1b-1be2-4433-97d5-a9254dcb3e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \n",
      "1: [UNK]\n",
      "2: recipeforpâtebrisée|inalargebowlblendtheflour,thebutter,thevegetableshortening,andthesaltuntilthemixtureresemblesmeal.add3tablespoonsicewater,tossthemixtureuntilthewaterisincorporated,andformthedoughintoaball.kneadthedoughlightlywiththeheelofthehandagainstasmoothsurfaceforafewsecondstodistributethefatevenlyandre-formitintoaball.dustthedoughwithflourandchillit,wrappedinwaxpaper,for1hour.\n",
      "3: coolingtemperature:80°f\n",
      "4: recipeforyogurtandlemondressing|inthejar,combinetheyogurt,lemonjuice,andsalt.coverwiththelidandshaketoblend.tasteforseasoning.thedressingcanbeusedimmediately.(storethedressingintherefrigeratorforupto1week.shaketoblendagainbeforeusing.)\n",
      "5: recipeforvanillaandalmondfrosting|usingelectricmixer,beatbutterinlargebowluntilfluffy.graduallybeatinsugar,thencreamandvanilla.dividebetween2bowls.mix1teaspoonvanillainto1bowlofbasefrosting.mixalmondextractintosecondbowlofbasefrosting.mixinyellowfoodcoloring,1dropatatime,untildesiredshadeisreached.\n",
      "6: recipeforturkeygravy|arrangerackincenterofovenandpreheatto425°f.inroastingpan,tossboneswith1/4cupoil.roastuntilwellbrowned,about20minutes.removefromovenandsetaside.inheavy,largepotovermoderatelylowheat,heatremaining1/4cupoiluntilhotbutnotsmoking.addgarlic,onions,celery,andcarrotsandsautéuntilgoldenbrown,16to18minutes.addpeppercornsandcontinuecookinguntilaromatic,2to3minutes.addbrandyandsimmer,uncovered,untilreducedbyhalf,about1minute.addturkeybones,chickenstock,anddemi-glaceandbringtoaboil.reduceheattolowandsimmeruntilthickenedandreducedbyhalf,2to21/2hours.strain,returntopot,andplaceovermoderatelylowheat.skimexcessfat,thenaddbasil,removefromheat,cover,andletsteep10minutes.straingravythroughcheesecloth-linedsieveintolargepot.stirinsaltandkeepwarm.\n",
      "7: recipeforturkeychili|covertheturkeypieceswithwaterandaddtheonionstuckwithcloves,thecelery,parsley,andpeppers.bringtoaboil.reducetheheat,skimoffanyscumwhichmayrisetothetop,andcoverthepot.simmeruntiltheturkeyistenderbutnotfallingfromthebones.removetheturkeypiecesandcooluntiltheycanbehandled.removethemeatfromthebonesingood-sizepieces.reducethebrothbyhalfoverabriskflame.youshouldhaveabout4cupsbroth.strainandadjustthesalt.addthechilipowder,thegreenchiles,andthegroundnutsandsimmeruntilthemixtureisthickened,smoothandwellblendedinflavor.youmayfindyoumaywishtoaddadditionalchilipowder.sautétheonion,garlic,andgreenpeppersintheoliveoil.addtothesauceandcookfor5minutes.addtheturkeymeatandcookthoroughly.addtheolivesandblanchedalmondsandreheatfor3minutes.servewithriceorpolentaandcrispfrenchbread.aradishandcucumbersaladwithavinaigrettesauceisgoodwiththis.tortillasareexcellentwiththechiliifyoudon'tservepolentaandfrenchbread.drinkbeer.\n",
      "8: recipefortraditionalfishstock|1.ina7-to8-quartstockpot,combinethefishbones,whitewine,andjustenoughwatertocover(youwon’tneedthefull2quartsofwaterhere).bringtoaboil,skimmingoffthewhitefoamfromthetopofthestockasitapproachesboiling,thenreducetheheatsothestocksimmers.(usingaladleandacircularmotion,pushthefoamfromthecentertotheoutsideofthepot,whereitiseasytoremove.)2.addtheonions,celery,carrots,bayleaves,parsley,thyme,andpeppercornsandstirthemintotheliquid.iftheingredientsarenotcoveredbytheliquid,addalittlemorewater.allowthestocktosimmergentlyfor20minutes.3.removethestockfromthestove,stiritagain,andallowittosteepfor10minutes.strainthroughafine-meshstrainerandseasonlightlywithsalt.ifyouarenotgoingtobeusingthestockwithinthehour,chillitasquicklyaspossible.coverthestockafterithascompletelycooledandkeeprefrigeratedforupto3days,orfreezeforupto2months.forequipment,youwillneeda7-to8-quartstockpot,aladle,andafine-meshstrainer.\n",
      "9: recipefortoprepareawaterbathforbaking|toprepareawaterbathforbaking,putyourfilledpaninalargerpanandaddenoughboiling-hotwatertoreachhalfwayupthesideofthesmallerpan.\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "import string \n",
    "import re \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "def pad_punctuation(s):\n",
    "    s = re.sub(f\"([{string.punctuation}])\", r' \\1 ', s)\n",
    "    s= re.sub(' +', '', s)\n",
    "    return s \n",
    "\n",
    "#Pad the punctuation marks, to treat them as separate words\n",
    "text_data = [pad_punctuation(x) for x in filtered_data]\n",
    "#Convert to a TensorFlow Dataset\n",
    "text_dataset = tf.data.Dataset.from_tensor_slices(text_data).batch(32).shuffle(1000)\n",
    "\n",
    "\"\"\"Create a Keras TextVectorization layer to convert text to lowercase, give the\n",
    "most prevalent 10,000 words a corresponding integer token, and trim or pad the\n",
    "sequence to 201 tokens long.\n",
    "\"\"\"\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=\"lower\",\n",
    "    max_tokens=10000,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=200 + 1,\n",
    ")\n",
    "# Apply the TextVectorization layer to the training data.\n",
    "vectorize_layer.adapt(text_dataset)\n",
    "#The vocab variable stores a list of the word tokens.\n",
    "vocab = vectorize_layer.get_vocabulary()\n",
    "\n",
    "\n",
    "# Display some token:word mappings\n",
    "for i, word in enumerate(vocab[:10]):\n",
    "    print(f\"{i}: {word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da5d636-021a-4b54-bede-d696ccb872d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an example of a recipe\n",
    "example_data = text_data[9]\n",
    "print(example_data)\n",
    "# Display the same example converted to ints\n",
    "example_tokenised = vectorize_layer(example_data)\n",
    "print(example_tokenised.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "806c0805-bb8f-4a95-96d9-a48ccd87fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentences = vectorize_layer(text)\n",
    "    x = tokenized_sentences[:, :-1]\n",
    "    y = tokenized_sentences[:, 1:]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_ds = text_dataset.map(prepare_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32828096-3440-4140-b12c-663142cf6824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers ,losses ,models \n",
    "\n",
    "#The Input layer does not need us to specify the sequence length in advance \n",
    "#(it can be flexible), so we use None as a placeholder.\n",
    "inputs = layers.Input(shape=(None,) , dtype = 'int32')\n",
    "#The Embedding layer requires two parameters, the size of the vocabulary \n",
    "#(10,000 tokens) and the dimensionality of the embedding vector (100).\n",
    "x = layers.Embedding(10000,100)(inputs)\n",
    "#The LSTM layers require us to specify the dimensionality of the\n",
    "#hidden vector (128) , and we choose to return the full sequence of the\n",
    "#hidden state.\n",
    "x = layers.LSTM(128,return_sequences = True)(x)\n",
    "# The Dense layer transforms the hidden states at each timestep into a\n",
    "#vector of probabilities for the next token.\n",
    "outputs = layers.Dense(10000, activation = 'softmax')(x)\n",
    "\n",
    "lstm = models.Model(inputs,outputs)\n",
    "\n",
    "loss_fn = losses.SparseCategoricalCrossentropy()\n",
    "#The model is compiled with SparseCategoricalCrossentropy loss—this is the\n",
    "#same as categorical cross-entropy, but is used when the labels are\n",
    "# integers rather than one-hot encoded vectors.\n",
    "lstm.compile(\"adam\", loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e992038e-ee1d-48e6-9af0-ae9ff7dd30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import callbacks\n",
    "# The TextGenerator callback function\n",
    "class TextGenerator(callbacks.Callback):\n",
    "    def __init__(self, index_to_word, top_k=10):\n",
    "        self.index_to_word = index_to_word\n",
    "        self.word_to_index = {\n",
    "            word: index for index, word in enumerate(index_to_word)\n",
    "        }  # <1>\n",
    "\n",
    "    def sample_from(self, probs, temperature):  # <2>\n",
    "        probs = probs ** (1 / temperature)\n",
    "        probs = probs / np.sum(probs)\n",
    "        return np.random.choice(len(probs), p=probs), probs\n",
    "\n",
    "    def generate(self, start_prompt, max_tokens, temperature):\n",
    "        start_tokens = [\n",
    "            self.word_to_index.get(x, 1) for x in start_prompt.split()\n",
    "        ]  # <3>\n",
    "        sample_token = None\n",
    "        info = []\n",
    "        while len(start_tokens) < max_tokens and sample_token != 0:  # <4>\n",
    "            x = np.array([start_tokens])\n",
    "            y = self.model.predict(x, verbose=0)  # <5>\n",
    "            sample_token, probs = self.sample_from(y[0][-1], temperature)  # <6>\n",
    "            info.append({\"prompt\": start_prompt, \"word_probs\": probs})\n",
    "            start_tokens.append(sample_token)  # <7>\n",
    "            start_prompt = start_prompt + \" \" + self.index_to_word[sample_token]\n",
    "        print(f\"\\ngenerated text:\\n{start_prompt}\\n\")\n",
    "        return info\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.generate(\"recipe for\", max_tokens=100, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f7b87f2-4e91-4294-9191-a964aa198334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_probs(info, vocab, top_k=5):\n",
    "    for i in info:\n",
    "        print(f\"\\nPROMPT: {i['prompt']}\")\n",
    "        word_probs = i[\"word_probs\"]\n",
    "        p_sorted = np.sort(word_probs)[::-1][:top_k]\n",
    "        i_sorted = np.argsort(word_probs)[::-1][:top_k]\n",
    "        for p, i in zip(p_sorted, i_sorted):\n",
    "            print(f\"{vocab[i]}:   \\t{np.round(100*p,2)}%\")\n",
    "        print(\"--------\\n\")\n",
    "\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"./checkpoint/checkpoint.ckpt\",\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f971e08-42cd-4f03-9304-19a7ab29ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize starting prompt\n",
    "text_generator = TextGenerator(vocab, lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a127848-34da-4c94-8f0b-d5687ecb1f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 0.3850\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 552s 871ms/step - loss: 0.3850\n",
      "Epoch 2/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 0.0216\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 482s 766ms/step - loss: 0.0216\n",
      "Epoch 3/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 0.0097\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 410s 652ms/step - loss: 0.0097\n",
      "Epoch 4/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 0.0014\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 496s 788ms/step - loss: 0.0014\n",
      "Epoch 5/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 8.3788e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 465s 736ms/step - loss: 8.3788e-04\n",
      "Epoch 6/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 7.6631e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 433s 688ms/step - loss: 7.6631e-04\n",
      "Epoch 7/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 7.2935e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 427s 680ms/step - loss: 7.2935e-04\n",
      "Epoch 8/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 7.0190e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 426s 677ms/step - loss: 7.0190e-04\n",
      "Epoch 9/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 6.7971e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 436s 693ms/step - loss: 6.7971e-04\n",
      "Epoch 10/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 6.5729e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 427s 679ms/step - loss: 6.5729e-04\n",
      "Epoch 11/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 6.3379e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 502s 799ms/step - loss: 6.3379e-04\n",
      "Epoch 12/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 6.1398e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 433s 688ms/step - loss: 6.1398e-04\n",
      "Epoch 13/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 5.9310e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 432s 687ms/step - loss: 5.9310e-04\n",
      "Epoch 14/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 5.6960e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 516s 820ms/step - loss: 5.6960e-04\n",
      "Epoch 15/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 5.5387e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 519s 825ms/step - loss: 5.5387e-04\n",
      "Epoch 16/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 5.5276e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 580s 923ms/step - loss: 5.5276e-04\n",
      "Epoch 17/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 5.1904e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 668s 1s/step - loss: 5.1904e-04\n",
      "Epoch 18/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 5.0411e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 531s 844ms/step - loss: 5.0411e-04\n",
      "Epoch 19/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 3.9869e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 520s 827ms/step - loss: 3.9869e-04\n",
      "Epoch 20/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 2.9600e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 481s 764ms/step - loss: 2.9600e-04\n",
      "Epoch 21/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 2.7540e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 408s 648ms/step - loss: 2.7540e-04\n",
      "Epoch 22/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 2.6399e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 405s 644ms/step - loss: 2.6399e-04\n",
      "Epoch 23/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 2.5729e-04\n",
      "generated text:\n",
      "recipe for [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] removestringandthinlyslicepork;coverandsetaside.reheatstockandcooknoodles recipeformelonandminttabbouleh|pourboilingwateroverbulgurinabowl,thencoverbowltightlyandletstand30minutes.draininasieveifwatery.meanwhile,purémintwithoilinablenderuntilsmooth.tossbulgurwithmintoil,limejuice,honeydew,onion,andsalt. [UNK] [UNK] [UNK] [UNK] \n",
      "\n",
      "629/629 [==============================] - 407s 646ms/step - loss: 2.5729e-04\n",
      "Epoch 24/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 2.3970e-04\n",
      "generated text:\n",
      "recipe for \n",
      "\n",
      "629/629 [==============================] - 416s 661ms/step - loss: 2.3970e-04\n",
      "Epoch 25/25\n",
      "629/629 [==============================] - ETA: 0s - loss: 2.2944e-04\n",
      "generated text:\n",
      "recipe for [UNK] \n",
      "\n",
      "629/629 [==============================] - 420s 668ms/step - loss: 2.2944e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fba769f4070>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.fit(\n",
    "    train_ds,\n",
    "    epochs=25,\n",
    "    callbacks=[model_checkpoint_callback, tensorboard_callback, text_generator],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf0cb9-d2a5-4a5e-9c5b-5ea4c5f28188",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop = False \n",
    "recipe_for = 'recipe for'\n",
    "while not stop:\n",
    "    text = input('Which recipe do you want today?')\n",
    "    if text == 'stop' or text == 'exit' :\n",
    "        stop = True\n",
    "    else:\n",
    "        recipe = recipe_for + ' ' + text\n",
    "        info = text_generator.generate(start_prompt =recipe,\n",
    "                                       max_tokens = 100\n",
    "                                       , temperature = 0.2)\n",
    "        print('With the probabilities : \\n ')\n",
    "        print_probs(info ,vocab)\n",
    "        print('Done!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32c1594-af6d-48fe-af18-5ef76c4af030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall Stacked LSTMS \n",
    "text_in = layers.Input(shape = (None,))\n",
    "embedding = layers.Embedding(total_words,embedding_size)(text_in)\n",
    "x = layers.LSTM(n_units,return_sequences = True)(x)\n",
    "x = layers.LSTM(n_units,return_sequences = True)(x)\n",
    "probabilities = layers.Dense(10000, activation = 'softmax')(x)\n",
    "\n",
    "model = models.Model(text_in , probavilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c54e2870-947b-4498-afad-cdaef74e9f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated text:\n",
      "recipe for chocolate ice cream | [UNK]\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream |\n",
      "[UNK]:   \t52.78%\n",
      ":   \t29.8%\n",
      "removestringandthinlyslicepork;coverandsetaside.reheatstockandcooknoodles:   \t1.48%\n",
      "scatteroverthemintorbasiltoserve.:   \t1.16%\n",
      "smoothaspossibletogiveacreamymixture.oncethetartbaseshavesetandarefeelingfirm,:   \t1.04%\n",
      "--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for chocolate ice cream |\", max_tokens=7, temperature=1.0\n",
    ")\n",
    "print_probs(info, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7581f297-ebea-4e9b-8def-eb13aefd1fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generated text:\n",
      "recipe for chocolate ice cream | [UNK]\n",
      "\n",
      "\n",
      "PROMPT: recipe for chocolate ice cream |\n",
      "[UNK]:   \t94.57%\n",
      ":   \t5.43%\n",
      "removestringandthinlyslicepork;coverandsetaside.reheatstockandcooknoodles:   \t0.0%\n",
      "scatteroverthemintorbasiltoserve.:   \t0.0%\n",
      "smoothaspossibletogiveacreamymixture.oncethetartbaseshavesetandarefeelingfirm,:   \t0.0%\n",
      "--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = text_generator.generate(\n",
    "    \"recipe for chocolate ice cream |\", max_tokens=7, temperature=0.2\n",
    ")\n",
    "print_probs(info, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101915c4-9cdd-43b8-b709-80f56ab62674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
